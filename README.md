Proof of concept-implementation of this paper in java: https://huggingface.co/papers/2309.12499

**NEWS**: Finally!!!! First test launched of the algorithm that is doing something. The llm is already invoked to recover the parts to be embedded in the repository... You can look at the class jmdevall.opencodeplan.application.CodePlanTest.java


I am doing the tests locally by starting the oobatextgen, using as a model a quantized Phind model of 33B parameters that TheBloke has available (https://huggingface.co/TheBloke), thank you! It is certain that there will be better models today but I do not know what the state of the art is like right now.

Specifically I am using this model: https://huggingface.co/TheBloke/Phind-CodeLlama-34B-v2-GGUF

I currently only have an 8Gb domestic graphics card so I can only run quantized models with 7B parameters on the GPU. I think it is insufficient, so it would be advisable to go for more advanced 33B models, which would require at least a 24Gb card...
I'm using a GGUF model on CPU on a ryzen 5600: very bad speed. I start it this way:

python server.py --model phind-codellama-34b-v2.Q5_K_M.gguf --threads 12 --n_ctx 16384 --api --verbose

Once started ooba raises the api on port 5000

ATTENTION: this project is still incomplete. It is not functional. However, certain parts can be seen and there are loose components. For now the perfect definition is that this project is chaos.


I have tried to follow a clean architecture, in order to be able to change the parts that are not properly part of the algorithm. These external parts are:

- the llm
- the code repository
- the parser/dependency analyzer

I have followed the package structure suggested here:
https://tbuss.de/posts/2023/9-how-to-do-the-package-structure-in-a-ports-and-adapter-architecture/

The objective is to separate the parts that belong to the algorithm from those that do not, so that whoever wants to can reuse as much as possible.

FAQ:
What is your goal with this project?

Personally, I have been trying other projects that use AI and act as assistants or are capable of generating code. For example:

https://github.com/paul-gauthier/aider, https://github.com/genia-dev/GeniA etc.

The fundamental idea of the "codeplan" paper is to take advantage of the information on the project's dependencies to generate the most specific prompt possible. Make small changes little by little throughout the code base.
The difficulty that attendees seem to currently encounter is:
- 1 manage to gather the relevant information to make a change.
- 2 Print the result of the llm as a change back in the repository.
The paper seems to have solved these two problems: it suggests using the language's own semantic information to obtain the dependencies of the parts involved in the code. This, together with the previous changes, would allow us to obtain the perfect prompt. On the other hand, when making small changes that only affect the code of one class at a time, in principle it is easier to transfer those changes back to the repository, while at the same time they serve to categorize the type of change and thus feed back to the prompt in future modifications.

In any case, the conclusion that seems to prevail is that, the smaller the change and the more controlled it is, the easier it is to take advantage of/interpret the result of the LLM, the easier it is to follow a methodical plan that allows working with large projects. In the paper, an algorithm, codeplan, is suggested, but I suggest going further: some other algorithm could be applied to this same idea... for example... the algorithm that follows the Test Driven Development methodology or whatever is dictated by the plan generated by an agent at a higher level to guide development.
In any case, my only intention is that this can serve as help or inspiration for any other project

Why java and not python?
For many reasons:
1 I am more used to working with java
2 Java is a language widely used in projects in the business world. In practice I think it would be the language that could be used the most.
3 Java is a strongly typed language. As the paper indicates, the algorithm is more appropriate and easier to implement in this type of languages.
4 Python seems more suitable for the particular world of artificial intelligence... it might seem that it is easier to implement in python. However, I don't really use anything extraordinary that requires any specialized bookstore. For me, the llm is simply an external web service to which you put a String and it returns another String. The most complex thing in this case is the Java parser and obtaining the dependencies. Furthermore, since I wanted to reuse something already done, there were few options beyond the javaparser library.

Why do you use javaparser and not use tree-setter as a parser as the paper indicates?
That was my first attempt, but I ran into 2 problems:
1) The java version is linked using a native library. In my case I couldn't get it to work, it gave me core dumps and I couldn't find the reason.
2) In addition to the parser, to find the dependencies it is very useful that the library also implements a "typesolver". This is already given to you by javaparser while for tree-setter I think there is nothing.

Of course, if you want to collaborate, participate, suggest things, ask whatever you want... this is a free project